{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports, Functions, Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from langchain import PromptTemplate\n",
    "import random\n",
    "\n",
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that loads a file with .rff extension and separate the values when the | character is found\n",
    "def LoadRFF_to_Pandas(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content] \n",
    "    content = [x.split('|') for x in content]\n",
    "    df = pd.DataFrame(content)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Define a function that stores several prompts in a list from random concepts\n",
    "def ComputePrompts(df, n, prompt_template):\n",
    "    prompts = []\n",
    "    concepts = []\n",
    "    df_sample = df.sample(n, replace=True)\n",
    "    for index, row in df_sample.iterrows():\n",
    "        prompts.append(prompt_template.format(CONCEPT = row['STR']))\n",
    "        concepts.append(row['STR'])\n",
    "    return prompts, concepts\n",
    "\n",
    "# Define a function that stores several prompts in a list from random concepts\n",
    "def ComputePrompts2(concept_list, n, prompt_template):\n",
    "    prompts = []\n",
    "    concepts = []\n",
    "    sampled_concepts = random.choices(concept_list, k=n)  # Randomly sample n concepts from the list\n",
    "    for concept in sampled_concepts:\n",
    "        prompts.append(prompt_template.format(CONCEPT=concept))\n",
    "        concepts.append(concept)\n",
    "    return prompts, concepts\n",
    "\n",
    "\n",
    "# Function that loads a file with .rff extension and separate the values when the | character is found\n",
    "def LoadRFF_to_Pandas(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content] \n",
    "    content = [x.split('|') for x in content]\n",
    "    df = pd.DataFrame(content)\n",
    "    return df\n",
    "\n",
    "\n",
    "def PrepareUMLS(root_path):\n",
    "\n",
    "    concept_names_POR = LoadRFF_to_Pandas(f'{root_path}/MRCONSO.RRF')\n",
    "    concept_names_POR = concept_names_POR[[0, 7, 14]]\n",
    "    # Rename the columns\n",
    "    concept_names_POR.columns = ['CUI', 'AUI', 'STR']\n",
    "\n",
    "    definitions_POR = LoadRFF_to_Pandas(f'{root_path}/MRDEF.RRF')\n",
    "    definitions_POR = definitions_POR[[0, 1, 5]]\n",
    "    # Rename the columns\n",
    "    definitions_POR.columns = ['CUI', 'AUI', 'DEF']\n",
    "\n",
    "    # Right join to get the definitions of the diseases\n",
    "    concepts_def_POR = pd.merge(concept_names_POR, definitions_POR, on = ['CUI', 'AUI'], how='left')\n",
    "\n",
    "    # Sort the dataframe by the STR column, and for the same value sort by the DEF column\n",
    "    concepts_def_POR = concepts_def_POR.sort_values(by=['CUI', 'DEF'])\n",
    "    # Drop duplicates based on the STR column\n",
    "    concepts_def_POR = concepts_def_POR.drop_duplicates(subset=['CUI'], keep='first')\n",
    "\n",
    "    semantic_types_POR = LoadRFF_to_Pandas(f'{root_path}/MRSTY.RRF')\n",
    "    semantic_types_POR = semantic_types_POR[[0, 3]]\n",
    "    # Rename the columns\n",
    "    semantic_types_POR.columns = ['CUI', 'STY']\n",
    "\n",
    "    # Left join to get the definitions of the diseases\n",
    "    concepts_def_POR = pd.merge(concepts_def_POR, semantic_types_POR, on = ['CUI'], how='left')\n",
    "    display(concepts_def_POR)\n",
    "\n",
    "    return concepts_def_POR\n",
    "\n",
    "\n",
    "def CreateVectorStore(file_paths, client):\n",
    "    vector_store = client.beta.vector_stores.create(name=\"Electronic Health Records\")\n",
    "    file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "    file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "    vector_store_id=vector_store.id, files=file_streams\n",
    "    )\n",
    "    print(f\"File batch status: {file_batch.status}\")\n",
    "    print(f\"File batch counts: {file_batch.file_counts}\")\n",
    "    print(f\"Vector store ID: {vector_store.id}\")\n",
    "\n",
    "    return vector_store\n",
    "\n",
    "\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    def __init__(self, client):\n",
    "        super().__init__()\n",
    "        self.client = client\n",
    "\n",
    "    @override\n",
    "    def on_message_done(self, message) -> None:\n",
    "        message_content = message.content[0].text\n",
    "        annotations = message_content.annotations\n",
    "        citations = []\n",
    "        for index, annotation in enumerate(annotations):\n",
    "            message_content.value = message_content.value.replace(\n",
    "                annotation.text, f\"[{index}]\"\n",
    "            )\n",
    "            if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "                cited_file = self.client.files.retrieve(file_citation.file_id)\n",
    "                citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "\n",
    "def GenerateSyntheticEHRs(client, user_prompts, assistant_id, vector_store_id, output_path, start_id=0, benchmark='semclinbr'):\n",
    "    full_responses = []\n",
    "    responses = []\n",
    "    pbar = tqdm(enumerate(user_prompts), total=len(user_prompts))\n",
    "\n",
    "    for index, prompt in pbar:\n",
    "        thread = client.beta.threads.create(messages=[ { \"role\": \"user\", \"content\": prompt} ],\n",
    "                                            tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store_id]}},\n",
    "                                            )\n",
    "        \n",
    "        pbar.set_description(f\"Thread ID: {thread.id}\")\n",
    "        \n",
    "        with client.beta.threads.runs.stream(thread_id=thread.id,\n",
    "                                             assistant_id=assistant_id,\n",
    "                                             event_handler=EventHandler(client)\n",
    "                                             ) as stream: stream.until_done()\n",
    "\n",
    "        # Retrieve the messages from the thread\n",
    "        messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "        # Retrieve the response from the messages\n",
    "        full_response = messages.data[0].content[0].text.value\n",
    "        if benchmark == 'semclinbr':\n",
    "            # Retrieve the response from the messages after removing irrelevant characters\n",
    "            response = messages.data[0].content[0].text.value[7:-4]\n",
    "        elif benchmark == 'portugueseclinicalner':\n",
    "            # Retrieve the response from the messages after removing irrelevant characters\n",
    "            response = messages.data[0].content[0].text.value[13:-4]\n",
    "        else:\n",
    "            raise ValueError('Benchmark not recognized. Please choose between \"semclinbr\" and \"portugueseclinicalner\"')\n",
    "\n",
    "        full_responses.append(full_response)\n",
    "        responses.append(response)\n",
    "\n",
    "        if benchmark == 'semclinbr':\n",
    "            # Store the response in a XML file in a given path\n",
    "            with open(f\"{output_path}/{1000+index+start_id}.xml\", \"w\") as f:\n",
    "                f.write(response)\n",
    "\n",
    "        elif benchmark == 'portugueseclinicalner':\n",
    "            # Store the response in a XML file in a given path\n",
    "            with open(f\"{output_path}/syntheticEHR_{index+start_id}_annotatedNER.conll\", \"w\") as f:\n",
    "                f.write(response)\n",
    "\n",
    "        else:\n",
    "            raise ValueError('Benchmark not recognized. Please choose between \"semclinbr\" and \"portugueseclinicalner\"')\n",
    "\n",
    "    return full_responses, responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key here\n",
    "api_key = \"<your_api_key>\"\n",
    "# Set your API key here\n",
    "project_id = \"<your_project_id>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare UMLS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts_def_POR = PrepareUMLS(root_path=\"<your_umls_data_path>\")\n",
    "\n",
    "neurological_diseases = [\n",
    "    \"Epilepsia\",\n",
    "    \"Esclerose Múltipla\",\n",
    "    \"Doença de Alzheimer\",\n",
    "    \"Doença de Parkinson\",\n",
    "    \"Enxaqueca\",\n",
    "    \"Acidente Vascular Cerebral (AVC)\",\n",
    "    \"Neuropatia Diabética\",\n",
    "    \"Esclerose Lateral Amiotrófica (ELA)\",\n",
    "    \"Meningite\",\n",
    "    \"Encefalite\",\n",
    "    \"Miastenia Gravis\",\n",
    "    \"Síndrome de Guillain-Barré\",\n",
    "    \"Neuralgia do Trigémeo\",\n",
    "    \"Neuropatia Periférica\",\n",
    "    \"Síndrome das Pernas Inquietas\",\n",
    "    \"Hidrocefalia\",\n",
    "    \"Demência com Corpos de Lewy\",\n",
    "    \"Paralisia de Bell\",\n",
    "    \"Doença de Huntington\",\n",
    "    \"Espondilose Cervical\",\n",
    "    \"Doença de Creutzfeldt-Jakob\",\n",
    "    \"Síndrome Pós-Poliomielite\",\n",
    "    \"Malformação de Chiari\",\n",
    "    \"Síndrome de Tourette\",\n",
    "    \"Neurofibromatose\",\n",
    "    \"Ataxia de Friedreich\",\n",
    "    \"Neuralgia Pós-Herpética\",\n",
    "    \"Doença de Wilson\",\n",
    "    \"Síndrome de Arnold-Chiari\",\n",
    "    \"Síndrome de Lennox-Gastaut\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SemClinBr augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare user prompts and system instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instruction = '''You are an advanced AI language model that generates and annotates synthetic health reports in Portuguese. Your task is to generate high-quality health reports and provide accurate Named Entity Recognition annotations based on the provided definitions and examples.\n",
    "\n",
    "### Guidelines:\n",
    "1. Language: Generate text in Portuguese.\n",
    "2. Health Report Context: Ensure the text reflects typical health report scenarios. Follow the structure of the reports uploaded to the system instructions.\n",
    "3. Annotations: Annotate entities accurately using the provided definitions and examples. Follow the format used in the file examples uploaded to the system instructions.\n",
    "\n",
    "### Annotation Tag Definitions:\n",
    "1. Disease or Syndrome: A condition that affects the body or mind, with specific symptoms and signs.\n",
    "2. Sign or Symptom: Signs are objective evidence of disease perceptible to the examining physician, while symptoms are the patient's subjective experiences.\n",
    "3. Quantitative Concept: A concept that represents measurable quantities. These could include physical quantities, such as length or mass.\n",
    "4. Laboratory or Test Result: The outcome of a laboratory test or diagnostic procedure. This result provides information about the extent of disease, condition, or abnormality.\n",
    "5. Diagnostic Procedure: A medical process to determine the presence, extent, or cause of a disease or condition. Diagnostic procedures include laboratory tests, biopsies, and other methods used to diagnose medical conditions.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Considering the system instructions given and the files uploaded to it, generate a complete, extensive, and high-quality electronic health report, with around 40 entities for tag annotation across all annotation tags, for a patient with the following condition: \"{CONCEPT}\". Generate annotations according to the annotation tag definitions, while considering all the tags mentioned in it. Also, pay close attention to how the tags were used in the uploaded file examples. Use several abbreviations just like in the file examples uploaded. Generate an XML file format like the text files I uploaded. Your output/response should only have the generated file.\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=[\"CONCEPT\"],\n",
    "                                 template = template\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 300\n",
    "prompts, concepts = ComputePrompts(concepts_def_POR, N, prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SDG using OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a client\n",
    "client = OpenAI(project=project_id, api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare EHRs to add to the assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\"real_ehr_example_01.txt\", \n",
    "                \"real_ehr_example_02.txt\",\n",
    "                \"real_ehr_example_03.txt\",\n",
    "                \"real_ehr_example_04.txt\"\n",
    "                ]\n",
    "\n",
    "vector_store = CreateVectorStore(file_paths, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an assistant\n",
    "temperature = 0.5\n",
    "top_p = 0.5\n",
    "model = \"gpt-4o-2024-08-06\"\n",
    "\n",
    "assistant = client.beta.assistants.create(name=\"Electronic Health Records Assistant\",\n",
    "                                          instructions=system_instruction,\n",
    "                                          model=model,\n",
    "                                          tools=[{\"type\": \"file_search\"}],\n",
    "                                          #tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    "                                          temperature=temperature,\n",
    "                                          top_p=top_p\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate GPT-4o SEHRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_responses, responses = GenerateSyntheticEHRs(client=client,\n",
    "                                                  user_prompts=prompts, \n",
    "                                                  assistant_id=assistant.id, \n",
    "                                                  vector_store_id=vector_store.id,\n",
    "                                                  output_path=\"<your_output_path>\",\n",
    "                                                  start_id=1\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PortugueseClinicalNER augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare user prompts and system instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instruction = '''You are an advanced AI language model that generates and annotates synthetic health reports in Portuguese. Your task is to generate high-quality health reports and provide accurate Named Entity Recognition annotations based on the provided definitions and examples.\n",
    "\n",
    "### Guidelines:\n",
    "1. Language: Generate text in European Portuguese.\n",
    "2. Health Report Context: Ensure the text reflects typical health report scenarios. Follow the structure of the reports uploaded to the system instructions.\n",
    "3. Annotations: Annotate entities accurately using the provided definitions and examples. Follow the format used in the file examples uploaded to the system instructions.\n",
    "\n",
    "### Annotation Tag Definitions:\n",
    "1. THER: This tag identifies references to therapeutic interventions, including medications, treatments, and procedures used for patient management. \n",
    "2. C: This tag highlights descriptions of medical conditions, symptoms, or diagnoses. \n",
    "3. OBS: This tag is used for supplementary clinical observations that do not necessarily describe a medical condition but provide additional information about the patient's state.\n",
    "4. DT: This tag marks temporal information, including specific dates, timeframes, or durations relevant to the patient's history or condition.\n",
    "5. CH: This tag captures descriptive details that characterize conditions, symptoms, or findings.\n",
    "6. R: This tag refers to the outcomes or findings from diagnostic tests, examinations, or treatments.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Considering the system instructions given and the files uploaded to it, generate a complete, extensive, and high-quality electronic health report, with around 40 entities for tag annotation across all annotation tags, for a patient with the following condition: \"{CONCEPT}\". Generate annotations according to the annotation tag definitions, while considering all the tags mentioned in it. Also, pay close attention to how the tags were used in the uploaded file examples. Use several abbreviations just like in the file examples uploaded. Generate a CoNLL-2003 file format like the text files I uploaded. Your output/response should only have the generated file.\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=[\"CONCEPT\"],\n",
    "                                 template = template\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "prompts, concepts = ComputePrompts2(neurological_diseases, N, prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SDG using OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a client\n",
    "client = OpenAI(project=project_id, api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare EHRs to add to the assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\"real_ehr_example_01.txt\", \n",
    "                \"real_ehr_example_02.txt\",\n",
    "                \"real_ehr_example_03.txt\",\n",
    "                \"real_ehr_example_04.txt\",\n",
    "                ]\n",
    "\n",
    "vector_store = CreateVectorStore(file_paths, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an assistant\n",
    "temperature = 0.5\n",
    "top_p = 0.5\n",
    "model = \"gpt-4o-2024-08-06\"\n",
    "\n",
    "assistant = client.beta.assistants.create(name=\"Electronic Health Records Assistant\",\n",
    "                                          instructions=system_instruction,\n",
    "                                          model=model,\n",
    "                                          tools=[{\"type\": \"file_search\"}],\n",
    "                                          #tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    "                                          temperature=temperature,\n",
    "                                          top_p=top_p\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate GPT-4o v3 SEHRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_responses, responses = GenerateSyntheticEHRs(client=client,\n",
    "                                                  user_prompts=prompts, \n",
    "                                                  assistant_id=assistant.id, \n",
    "                                                  vector_store_id=vector_store.id,\n",
    "                                                  output_path=\"<your_output_path>\",\n",
    "                                                  start_id=1,\n",
    "                                                  benchmark='portugueseclinicalner'\n",
    "                                                  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
